{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "first-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Using cached yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Using cached multitasking-0.0.10-py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.9/site-packages (from yfinance) (1.3.5)\n",
      "Requirement already satisfied: lxml>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from yfinance) (4.6.4)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.9/site-packages (from yfinance) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.9/site-packages (from yfinance) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24->yfinance) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->yfinance) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->yfinance) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->yfinance) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->yfinance) (2.10)\n",
      "Installing collected packages: multitasking, yfinance\n",
      "Successfully installed multitasking-0.0.10 yfinance-0.1.67\n",
      "Collecting pandas_datareader\n",
      "  Using cached pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.9/site-packages (from pandas_datareader) (4.6.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from pandas_datareader) (2.25.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.9/site-packages (from pandas_datareader) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->pandas_datareader) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->pandas_datareader) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->pandas_datareader) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas_datareader) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pandas_datareader) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pandas_datareader) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pandas_datareader) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pandas_datareader) (2.10)\n",
      "Installing collected packages: pandas-datareader\n",
      "Successfully installed pandas-datareader-0.10.0\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.9\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "!pip install pandas_datareader\n",
    "!pip install tabulate \n",
    "\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import tabulate \n",
    "import pickle\n",
    "\n",
    "#external data & file reading\n",
    "import pandas_datareader as pdr\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "#for plotting\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-english",
   "metadata": {},
   "source": [
    "## Constructing a First Portfolio\n",
    "\n",
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "advised-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets trade info for the specified countries. This will be updated to all 37 in time! But for now just well developed\n",
    "#asian countries as it is too slow for my pc. \n",
    "\n",
    "countries_with_trade_info = ['CHINA','HONG KONG','JAPAN','KOREA','TAIWAN']\n",
    "trades_list = []\n",
    "for i in countries_with_trade_info:\n",
    "    trades_list.append(pd.read_csv(i + \".csv\"))\n",
    "all_trades  = pd.concat(trades_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-methodology",
   "metadata": {},
   "source": [
    "#### Filtering & Getting initial metrics\n",
    "\n",
    "The code below shows that we have a total of 3,135 companies which match our initial criteria. From here we'd now like to filter further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sealed-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At first we are to look at just all sector data. So this filters to the sector \"All Sectors\"\n",
    "data = all_trades[all_trades['Sector'] == \"All_sectors\"]\n",
    "\n",
    "#And now we collect the unique companies for which this filtered data corresponds to. \n",
    "#all_sector_trades['fsym_id'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-moldova",
   "metadata": {},
   "source": [
    "#### Filter by Year\n",
    "\n",
    "This will ensure that the stocks we take we have traded in the set year / years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "imposed-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2021\"\n",
    "\n",
    "#1.6 million missing end dates!\n",
    "data['Exit Date'].isna().sum() \n",
    "\n",
    "#No missing start dates!\n",
    "data['Date'].isna().sum() \n",
    "\n",
    "years = []\n",
    "for element in data['Date']:\n",
    "    years.append(element[:4])\n",
    "\n",
    "data['Year'] = years\n",
    "\n",
    "data = data[data.Year == year]\n",
    "\n",
    "#we traded 3022 unique stocks in the previous year. \n",
    "#len(data['fsym_id'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-baghdad",
   "metadata": {},
   "source": [
    "#### Filter by Factor\n",
    "\n",
    "This will filter based on factor level. Pass in a number and the factor and it will return an ordered dataframe of potential stocks by average return in the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "preceding-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data #data for all the trades we are investigating \n",
    "factor = \"Volatility\" #factor to investigate\n",
    "n = 30 #number of stocks to return\n",
    "\n",
    "def factor_filter(data,factor,n): \n",
    "    company_data = data[data.Factor == factor]\n",
    "\n",
    "    company_data = company_data.groupby(['fsym_id']).mean()\n",
    "    company_data = company_data.sort_values('returns', ascending = False)\n",
    "    company_data = company_data.drop(['Unnamed: 0'], axis=1)\n",
    "    selected = company_data.head(n) \n",
    "    return selected \n",
    "    \n",
    "d = factor_filter(data,factor,n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-found",
   "metadata": {},
   "source": [
    "#### Constructing the Portfolio - Incoprorating Risk Behaviours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-telescope",
   "metadata": {},
   "source": [
    "#### Constructing the Portfolio - selecting number of stocks for a given profile\n",
    "\n",
    "This bit is slightly more complex. It takes a set $n$, and risk profile as for example is given above and determines the number of stocks (and then makes appropriate calls to the prev. function) to construct the portfolio. To determine the weightings, I first guess and use the system describe below.\n",
    "\n",
    "\n",
    "$$\\begin{cases}\n",
    "\\text{1 weighting points: Low} \\\\ \n",
    "\\text{3 weighting points: Medium} \\\\\n",
    "\\text{5 weighting points: High} \\end{cases} $$\n",
    "\n",
    "This can easily be changed, this is just for my first initial guess. For example. For someone who wants a safe portfolio, the \"volatility\" factor will be assigned Low, wheras we would see the dividend factor assigned \"high\". I make initial guesses as to appropriate set ups for these weightings by risk tolerance in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "immediate-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data['Factor'].unique()\n",
    "\n",
    "#type 1 represents someone who is not risky - needs changed and interpreted and justified!\n",
    "type_1 = [3,1,5,5,3,3,5,1,\"Type 1\"]\n",
    "\n",
    "#type 2 is someone who is not risky / average\n",
    "type_2 = [3,3,5,5,3,3,5,3,\"Type 2\"]\n",
    "\n",
    "#type 3 is average\n",
    "type_3 = [3,3,3,3,3,3,3,3,\"Type 3\"]\n",
    "\n",
    "#type 4 - risky ish\n",
    "type_4 = [1,5,3,3,5,3,1,5,\"Type 4\"]\n",
    "\n",
    "#type 5 - someone risky\n",
    "type_5 = [1,5,3,1,5,1,1,5,\"Type 5\"]\n",
    "\n",
    "col_names = list(names)\n",
    "col_names.append(\"Type\")\n",
    "\n",
    "types = [type_1,type_2,type_3,type_4,type_5]\n",
    "df = pd.DataFrame(columns = col_names)\n",
    "for i in types:\n",
    "    a_series = pd.Series(i, index = df.columns)\n",
    "    df = df.append(a_series, ignore_index=True)\n",
    "    \n",
    "df = df.set_index('Type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "passive-tactics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsym_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P8ZTFP-R</th>\n",
       "      <td>0.176711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DY978H-R</th>\n",
       "      <td>0.148645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVZYGZ-R</th>\n",
       "      <td>0.145620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R46SYN-R</th>\n",
       "      <td>0.138662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQCPW9-R</th>\n",
       "      <td>0.138116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBMG3G-R</th>\n",
       "      <td>0.213008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HZ28DF-R</th>\n",
       "      <td>0.175422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JS497J-R</th>\n",
       "      <td>0.174260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHVF2G-R</th>\n",
       "      <td>0.162166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R95BNM-R</th>\n",
       "      <td>0.159557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           returns\n",
       "fsym_id           \n",
       "P8ZTFP-R  0.176711\n",
       "DY978H-R  0.148645\n",
       "MVZYGZ-R  0.145620\n",
       "R46SYN-R  0.138662\n",
       "SQCPW9-R  0.138116\n",
       "...            ...\n",
       "VBMG3G-R  0.213008\n",
       "HZ28DF-R  0.175422\n",
       "JS497J-R  0.174260\n",
       "SHVF2G-R  0.162166\n",
       "R95BNM-R  0.159557\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beh_type = 1\n",
    "n= 200\n",
    "\n",
    "weightings = df.iloc[beh_type -1]\n",
    "total_weighting_points = sum(weightings)\n",
    "weights = []\n",
    "\n",
    "for i in range (0,len(names)):\n",
    "    weights.append(weightings[i]/total_weighting_points)   \n",
    "\n",
    "weights = np.round(weights,2)\n",
    "weights =  weights*n\n",
    "weights = weights.astype(int)\n",
    "\n",
    "\n",
    "if sum(weights) > n:\n",
    "    remove = sum(weights) % n \n",
    "    for j in range(0,remove):\n",
    "        drop = random.randint(0,len(names)-1)\n",
    "        weights[drop] -= 1 \n",
    "        \n",
    "elif sum(weights) < n:\n",
    "    add = sum(weights) % n \n",
    "    for j in range(0,add):\n",
    "        drop = random.randint(0,len(names)-1)\n",
    "        weights[drop] += 1 \n",
    "        \n",
    "df_list = [] \n",
    "\n",
    "for i in range (0,len(names)):\n",
    "    factor_name = names[i]\n",
    "    df_list.append(factor_filter(data,factor_name,int(weights[i])))\n",
    "    \n",
    "frame = pd.concat(df_list)\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "billion-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean returns from previous year. \n",
    "np.mean(frame['returns'])\n",
    "\n",
    "df_list2 = []\n",
    "for i in names:\n",
    "    df2 = data[data['Factor'] == i]\n",
    "    df2 = df2.dropna()\n",
    "    df2 = df2.head(20)\n",
    "    df2 = np.mean(df2['returns'])\n",
    "    df_list2.append(df2)\n",
    "\n",
    "df_list2\n",
    "df = pd.DataFrame(columns = names)\n",
    "\n",
    "a_series = pd.Series(df_list2, index = df.columns)\n",
    "df = df.append(a_series, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "external-demand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55375"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = pd.read_csv(\"mapping.csv\")\n",
    "\n",
    "company_names = pd.DataFrame(mappings['company_name'])\n",
    "company_names.reset_index(inplace=True,drop = True)\n",
    "company_names['fsym_id'] = mappings['fsym_id']\n",
    "\n",
    "len(data['fsym_id'].unique())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
